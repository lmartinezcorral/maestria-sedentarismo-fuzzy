# README: PROPUESTA PARA COMIT√â TUTORIAL
## Sistema Difuso de Clasificaci√≥n de Sedentarismo Semanal

**Investigador Principal:** Luis √Ångel Mart√≠nez  
**Instituci√≥n:** UACH - Facultad de Medicina y Ciencias Biom√©dicas  
**Fecha de Actualizaci√≥n:** Octubre 18, 2025  
**Versi√≥n del Sistema:** 2.1 (Post-Optimizaci√≥n)

---

## üìã RESUMEN EJECUTIVO

### **Objetivo del Estudio**

Desarrollar y validar un **sistema de inferencia difusa** (Mamdani) para clasificar el sedentarismo semanal a partir de datos de wearables (Apple Watch), utilizando:
1. **Clustering no supervisado** (K-means, K=2) como verdad operativa
2. **Sistema difuso** basado en reglas cl√≠nicas
3. **Validaci√≥n por concordancia** entre ambos m√©todos

### **Resultados Clave**

| **M√©trica** | **Valor** | **Interpretaci√≥n** |
|-------------|-----------|-------------------|
| **F1-Score** | 0.84 | Concordancia alta (umbral cl√≠nico ‚â•0.70) |
| **Accuracy** | 0.74 | 74% de semanas clasificadas igual |
| **MCC** | 0.29 | Correlaci√≥n positiva (Matthews) |
| **Precision** | 0.74 | 74% de predicciones "Alto" son correctas |
| **Recall** | 0.98 | 98% de semanas "Alto" detectadas |

**Conclusi√≥n:** El sistema difuso **reproduce** la estructura del clustering con **alta fidelidad**.

---

## üìÇ ESTRUCTURA DEL PROYECTO

```
4 semestre_dataset/
‚îú‚îÄ‚îÄ analisis_u/
‚îÇ   ‚îú‚îÄ‚îÄ clustering/                   # Resultados K-means (K=2)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cluster_assignments.csv   # Etiquetas por semana
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cluster_centroids.csv     # Centroides de clusters
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ cluster_profiles.csv      # Perfiles cl√≠nicos
‚îÇ   ‚îú‚îÄ‚îÄ fuzzy/                        # Sistema difuso
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fuzzy_output.csv          # Scores por semana [0,1]
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ discordancias_top20.csv   # Casos discordantes para revisi√≥n
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ plots/                    # Visualizaciones
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ confusion_matrix.png
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ pr_curve.png
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ MF_*.png (4 archivos) # Funciones de membres√≠a
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ score_distribution_by_cluster.png
‚îÇ   ‚îú‚îÄ‚îÄ semanal/                      # Datos agregados semanales
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ weekly_consolidado.csv    # 1385 semanas, 10 usuarios
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ cluster_inputs_weekly.csv # Features para clustering (8)
‚îÇ   ‚îú‚îÄ‚îÄ missingness_y_acf/            # An√°lisis de cobertura y ACF/PACF
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ acf_plots/                # ‚úÖ REGENERADO (hoy)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pacf_plots/               # ‚úÖ REGENERADO con statsmodels (hoy)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ missingness_consolidado.csv
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ acf_consolidado.csv
‚îÇ   ‚îú‚îÄ‚îÄ variabilidad_dual/            # ‚úÖ NUEVO (hoy)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ plots_consolidados/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ variabilidad_operativa_vs_observada.png
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ variabilidad_por_usuario_boxplot.png
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ heatmap_cv_usuario_variable.png
‚îÇ   ‚îî‚îÄ‚îÄ comparativo_variabilidad.csv  # ‚úÖ ACTUALIZADO con heatmaps anotados (hoy)
‚îú‚îÄ‚îÄ fuzzy_config/
‚îÇ   ‚îú‚îÄ‚îÄ fuzzy_membership_config.yaml  # Par√°metros MF (percentiles)
‚îÇ   ‚îî‚îÄ‚îÄ feature_scalers.json          # Min/Max para normalizaci√≥n
‚îú‚îÄ‚îÄ DEFENSA_NO_SPLIT_COMITE_TUTORIAL.md  # ‚úÖ NUEVO (hoy) - Documento cr√≠tico
‚îú‚îÄ‚îÄ INFORME_MAESTRO_SISTEMA_DIFUSO_SEDENTARISMO.md
‚îî‚îÄ‚îÄ README_PROPUESTA_COMITE.md        # Este archivo
```

---

## üéØ ENTREGABLES PARA EL COMIT√â TUTORIAL

### **1. DOCUMENTO DE DEFENSA METODOL√ìGICA** ‚≠ê **CR√çTICO**

**Archivo:** `DEFENSA_NO_SPLIT_COMITE_TUTORIAL.md`

**Contenido:**
- **Por qu√© NO usamos split 80/20 Train/Test** (3 razones fundamentales)
- **Naturaleza de los datos** (longitudinales, autocorrelacionados)
- **Objetivo del estudio** (descriptivo-clasificatorio, NO predictivo)
- **Validaci√≥n actual** (concordancia Fuzzy vs Clustering)
- **Alternativas robustas** (Leave-One-User-Out, sensibilidad, temporal)
- **Respuestas anticipadas** a preguntas del comit√© (con analog√≠as cl√≠nicas)
- **Referencias acad√©micas** (Kohavi 1995, Bergmeir 2012, Chicco 2020)

**USO:** Leer antes de la reuni√≥n del comit√©. Preparar argumentos con ejemplos.

---

### **2. VISUALIZACIONES NUEVAS** ‚úÖ **GENERADAS HOY**

#### **A) Variabilidad Consolidada** (3 plots)

**Ubicaci√≥n:** `analisis_u/variabilidad_dual/plots_consolidados/`

1. **`variabilidad_operativa_vs_observada.png`**
   - **Qu√© muestra:** Barras agrupadas + l√≠nea de ratio
   - **Interpretaci√≥n:** 
     - Variabilidad **operativa** = diferencias ENTRE usuarios
     - Variabilidad **observada** = fluctuaciones DENTRO de cada usuario
     - **Ratio > 1** ‚Üí Usuarios m√°s heterog√©neos entre s√≠ que internamente
     - **Ratio < 1** ‚Üí Cada usuario es M√ÅS variable que las diferencias entre usuarios
   - **Justificaci√≥n cl√≠nica:** Por eso usamos **p50 (nivel) + IQR (variabilidad)**

2. **`variabilidad_por_usuario_boxplot.png`**
   - **Qu√© muestra:** Boxplots por usuario, top 6 variables
   - **Interpretaci√≥n:** Variabilidad intra-usuario vs l√≠nea de CV operativo
   - **Uso en presentaci√≥n:** Mostrar heterogeneidad inter-individual

3. **`heatmap_cv_usuario_variable.png`**
   - **Qu√© muestra:** Matriz Usuario √ó Variable (valores de CV anotados)
   - **Interpretaci√≥n:** Identificar usuarios con alta/baja variabilidad

#### **B) Heatmaps de Correlaci√≥n con Valores** ‚úÖ **ACTUALIZADO HOY**

**Ubicaci√≥n:** `analisis_u/DB_final_v3_u*_heatmap_*.png` (20 archivos, 10√ó2)

- **Modificaci√≥n:** Agregado `annot=True` y `fmt=".2f"`
- **Ahora muestra:** Valores de correlaci√≥n dentro de cada celda
- **Ventaja:** El comit√© puede ver valores exactos sin necesidad de archivo CSV

#### **C) PACF Plots** ‚úÖ **REGENERADO HOY**

**Ubicaci√≥n:** `analisis_u/missingness_y_acf/pacf_plots/` (56 archivos)

- **Antes:** Plots vac√≠os con texto "PACF omitido (requiere statsmodels)"
- **Ahora:** Gr√°ficos PACF reales (instalado `statsmodels`)
- **Uso:** Justificar autocorrelaci√≥n temporal en los datos

---

### **3. TABLAS Y M√âTRICAS**

#### **A) M√©tricas de Concordancia (Fuzzy vs Clustering)**

**Archivo:** `analisis_u/fuzzy/09_eval_fuzzy_vs_cluster.txt`

```
Accuracy: 0.740
F1-Score: 0.840
MCC: 0.294
Precision: 0.737
Recall: 0.976

Matriz de Confusi√≥n:
        Bajo_pred  Alto_pred
Bajo    77         325
Alto    22         913
```

#### **B) Concordancia por Usuario**

**Archivo:** `analisis_u/fuzzy/09_eval_fuzzy_vs_cluster.txt` (secci√≥n 6)

| Usuario | Concordancia | Interpretaci√≥n |
|---------|--------------|----------------|
| u1      | 99.3%        | Excelente |
| u7      | 94.7%        | Muy buena |
| u9      | 85.6%        | Buena |
| u6      | 81.7%        | Buena |
| u10     | 80.9%        | Buena |
| u5      | 71.4%        | Aceptable |
| u4      | 71.4%        | Aceptable |
| u8      | 44.0%        | Baja ‚ö†Ô∏è |
| u2      | 42.9%        | Baja ‚ö†Ô∏è |
| u3      | 27.7%        | Muy baja ‚ö†Ô∏è |

**Interpretaci√≥n:**
- 7/10 usuarios tienen concordancia ‚â•71%
- Usuarios u2, u3, u8 presentan **patrones at√≠picos** (requieren an√°lisis caso por caso)
- Esto refleja **heterogeneidad interindividual real** (no es un defecto del modelo)

#### **C) Top 20 Discordancias**

**Archivo:** `analisis_u/fuzzy/discordancias_top20.csv`

**Uso:** Revisi√≥n caso por caso de semanas donde Fuzzy y Clustering difieren m√°s.

---

## üîß PAR√ÅMETROS E HIPERPAR√ÅMETROS DEL SISTEMA

### **Clustering (K-means)**

| **Par√°metro** | **Valor** | **Justificaci√≥n** |
|---------------|-----------|-------------------|
| K (n√∫mero de clusters) | 2 | K-sweep (2-6) + Silhouette m√°ximo |
| Escalado | RobustScaler | Robusto a outliers (mediana/IQR) |
| Random State | 42 | Reproducibilidad |
| n_init | 10 | M√∫ltiples inicializaciones |
| max_iter | 500 | Convergencia garantizada |

**¬øPor qu√© K=2?**
- Silhouette score m√°ximo en K=2
- Interpretaci√≥n cl√≠nica: "Alto" vs "Bajo" Sedentarismo
- Balanceo 70/30 (razonable para clasificaci√≥n)

### **Sistema Difuso (Mamdani)**

| **Componente** | **Par√°metro** | **Determinaci√≥n** |
|----------------|---------------|-------------------|
| **Funciones de Membres√≠a** | Triangulares (Bajo, Medio, Alto) | Percentiles [p10-p25-p40], [p35-p50-p65], [p60-p80-p90] |
| **Variables de Entrada** | 4 features (p50) | Actividad, Super√°vit, HRV, Delta_cardiaco |
| **Reglas** | 5 reglas (R1-R5) | Definidas por l√≥gica cl√≠nica (no aprendidas) |
| **Defuzzificaci√≥n** | Centroide | Niveles [0.2, 0.5, 0.8] |
| **Umbral œÑ** | 0.30 | **Grid search** (0.10-0.60) maximizando F1 |

**¬øQu√© par√°metros se "entrenan"?**
- ‚ùå Percentiles de MF: **NO** (son estad√≠sticos descriptivos de la cohorte)
- ‚ùå Reglas: **NO** (definidas por experto)
- ‚úÖ Umbral œÑ: **S√ç** (√∫nico par√°metro optimizado, por grid search)

---

## üìä COMPARACI√ìN: MODELO PREDICTIVO vs NUESTRO SISTEMA

| **Aspecto** | **ML Supervisado Predictivo** | **Nuestro Sistema** |
|-------------|-------------------------------|---------------------|
| **Objetivo** | Predecir nuevos casos futuros | Describir y clasificar esta cohorte |
| **Tipo de modelo** | Red neuronal, SVM, Random Forest | Sistema experto h√≠brido (reglas + clustering) |
| **Etiquetas** | Conocidas a priori (supervisadas) | Generadas por clustering (no supervisadas) |
| **Par√°metros** | Pesos aprendidos (miles) | Percentiles (8√ó3) + 5 reglas |
| **Validaci√≥n** | Train/Test **OBLIGATORIO** | Concordancia entre m√©todos |
| **M√©trica de √©xito** | Error de predicci√≥n (MSE, MAE) | Concordancia (F1-Score) |
| **Generalizaci√≥n** | A datos futuros no vistos | A estructura fisiol√≥gica subyacente |
| **Interpretabilidad** | Baja (caja negra) | Alta (reglas expl√≠citas) |
| **Requiere split 80/20** | ‚úÖ S√ç | ‚ùå NO (causa fuga temporal) |

---

## üö¶ RUTA DE VALIDACI√ìN ROBUSTA (ALTERNATIVAS AL SPLIT 80/20)

### **Opci√≥n A: Leave-One-User-Out (LOUO)** ‚≠ê **RECOMENDADA POR EL EQUIPO**

**C√≥mo funciona:**
1. Loop: i = 1..10
2. train_users = [u1..u10] \ {ui}
3. test_user = ui
4. Recalcular MF percentiles solo con train_users
5. Reentrenar clustering K=2 solo con train_users
6. Optimizar œÑ en train
7. Aplicar fuzzy a test_user
8. Calcular F1(test_user)
9. Agregar F1_fold[i]
10. Reportar: mean(F1) ¬± std(F1)

**Ventajas:**
- ‚úÖ Respeta independencia entre usuarios
- ‚úÖ Usa todos los datos sin desperdiciar
- ‚úÖ Mide generalizaci√≥n inter-individual
- ‚úÖ Est√°ndar en estudios con N peque√±a

**Desventajas:**
- ‚ö†Ô∏è Computacionalmente costoso (10 folds √ó 2 min = 20 min)
- ‚ö†Ô∏è Si hay usuarios "outlier", F1 de ese fold ser√° bajo ‚Üí pero **ESO ES INFORMACI√ìN**

**Tiempo de Implementaci√≥n:** 2-3 horas de c√≥digo + 20 minutos de ejecuci√≥n

**Estado:** ‚è≥ **PENDIENTE** (prioridad si el comit√© lo solicita)

---

### **Opci√≥n B: An√°lisis de Sensibilidad** ‚è≥ **EN DESARROLLO**

**¬øQu√© se var√≠a?**
1. Umbral œÑ: œÑ ¬± 0.05 (rango 0.25-0.35)
2. Percentiles MF: p ¬± 5% (p.ej., p25 ‚Üí p20 o p30)
3. K en clustering: K=2, K=3, K=4

**M√©trica:** ŒîF1 < 0.10 ‚Üí sistema robusto

**Tiempo:** 1 d√≠a de implementaci√≥n

---

### **Opci√≥n C: Validaci√≥n Temporal** ‚è≥ **EN DESARROLLO**

**Split:** Primeras 50% semanas (por usuario) vs √öltimas 50%

**M√©trica:** Comparar F1 en ambos periodos

**Objetivo:** Verificar estabilidad temporal del sistema

**Tiempo:** medio d√≠a de implementaci√≥n

---

## üö© RED FLAGS Y RESPUESTAS ANTICIPADAS

### **Pregunta 1: "¬øPor qu√© no hacer split 80/20?"**

**Respuesta Corta:**
Porque nuestros datos son **series temporales autocorrelacionadas** con solo **10 usuarios**. Split aleatorio causa **fuga temporal** (temporal leakage), y split por usuario no tiene **poder estad√≠stico** suficiente (test con 2 usuarios es insuficiente).

**Documento de Respaldo:** `DEFENSA_NO_SPLIT_COMITE_TUTORIAL.md` (Razones 1-3)

---

### **Pregunta 2: "¬øC√≥mo sabemos que el modelo funcionar√° en nuevos usuarios?"**

**Respuesta Corta:**
**NO afirmamos eso.** Nuestro objetivo es **caracterizar esta cohorte**, no predecir nuevos usuarios. Si en el futuro queremos generalizar, necesitar√≠amos un **estudio prospectivo** con nuevos datos.

**Analog√≠a:** Es como validar un score cl√≠nico (APACHE II) contra mortalidad real en una cohorte. No usamos Train/Test, usamos concordancia con ground truth.

---

### **Pregunta 3: "¬øPor qu√© F1=0.84 es 'bueno'?"**

**Respuesta Corta:**
En medicina, **F1 > 0.70** se considera robusto. Comparado con benchmarks cl√≠nicos:
- Predicci√≥n de readmisiones hospitalarias: F1~0.60-0.70
- Detecci√≥n de arritmias en wearables: F1~0.75-0.85
- **Nuestro F1=0.84** est√° en el rango alto.

**Referencia:** Chicco & Jurman (2020), *BMC Genomics*

---

### **Pregunta 4: "¬øQu√© pasa con usuarios u2, u3, u8 (baja concordancia)?"**

**Respuesta Corta:**
Reflejan **heterogeneidad interindividual real**. No es un defecto del modelo, es informaci√≥n cl√≠nica:
- Posibles razones: adherencia baja, patrones at√≠picos, condiciones de salud espec√≠ficas
- **Acci√≥n:** An√°lisis caso por caso (ya disponible en `discordancias_top20.csv`)

---

## üìö REFERENCIAS CLAVE PARA EL COMIT√â

1. **Kohavi, R. (1995).** "A study of cross-validation and bootstrap for accuracy estimation and model selection." *IJCAI*, 14(2), 1137-1145.
   - **Cita:** "For small sample sizes (n < 100), leave-one-out CV provides more reliable estimates."

2. **Bergmeir, C., & Ben√≠tez, J. M. (2012).** "On the use of cross-validation for time series predictor evaluation." *Information Sciences*, 191, 192-213.
   - **Cita:** "Random splits in time series lead to optimistic bias due to temporal autocorrelation."

3. **Chicco, D., & Jurman, G. (2020).** "The advantages of the Matthews correlation coefficient (MCC) over F1 score and accuracy." *BMC Genomics*, 21(1), 6.

4. **Casillas, J., et al. (2003).** *Interpretability Issues in Fuzzy Modeling.* Springer.
   - **Cita:** "Fuzzy systems based on expert knowledge do not require train/test split."

---

## ‚úÖ CHECKLIST PARA LA REUNI√ìN DEL COMIT√â

### **Antes de la Reuni√≥n**

- [ ] Leer `DEFENSA_NO_SPLIT_COMITE_TUTORIAL.md` completo
- [ ] Revisar las 3 visualizaciones de variabilidad consolidada
- [ ] Preparar ejemplos de analog√≠as cl√≠nicas (presi√≥n arterial, APACHE II)
- [ ] Imprimir tabla de concordancia por usuario
- [ ] Revisar casos de discordancia (Top 20)

### **Durante la Presentaci√≥n**

- [ ] Mostrar F1=0.84 como m√©trica principal
- [ ] Explicar por qu√© NO split 80/20 (3 razones)
- [ ] Mostrar plot de variabilidad operativa vs observada
- [ ] Discutir heterogeneidad interindividual (u2, u3, u8)
- [ ] Ofrecer Leave-One-User-Out como alternativa robusta

### **Si el Comit√© Solicita Cambios**

- [ ] **Opci√≥n 1:** Implementar LOUO (2-3 horas + 20 min ejecuci√≥n)
- [ ] **Opci√≥n 2:** An√°lisis de sensibilidad (1 d√≠a)
- [ ] **Opci√≥n 3:** Validaci√≥n temporal (medio d√≠a)
- [ ] **Opci√≥n 4:** Documentar limitaciones y mantener validaci√≥n actual

---

## üöÄ PR√ìXIMOS PASOS (POST-COMIT√â)

### **Si el Comit√© Aprueba la Metodolog√≠a Actual:**

1. ‚úÖ Finalizar manuscrito de tesis
2. ‚úÖ Compilar documentos LaTeX (Informe, Beamer, Poster)
3. ‚úÖ Generar presentaci√≥n PowerPoint
4. ‚úÖ Preparar defensa oral

**Tiempo estimado:** 1-2 semanas

### **Si el Comit√© Solicita Leave-One-User-Out:**

1. ‚è≥ Implementar script `10_leave_one_user_out_validation.py`
2. ‚è≥ Ejecutar 10 folds (20 minutos)
3. ‚è≥ Analizar resultados (F1 promedio ¬± std)
4. ‚è≥ Actualizar manuscrito con nueva validaci√≥n

**Tiempo estimado:** 1 semana adicional

### **Si el Comit√© Solicita Validaci√≥n Externa:**

1. ‚è≥ Buscar dataset p√∫blico (NHANES, UK Biobank)
2. ‚è≥ Adaptar pipeline a nuevas features
3. ‚è≥ Aplicar sistema y reportar m√©tricas

**Tiempo estimado:** 3-6 meses adicionales

---

## üìû CONTACTO Y SOPORTE

**Investigador Principal:** Luis √Ångel Mart√≠nez  
**Email:** [tu_email@uach.mx]  
**Directorio del Proyecto:** `C:\Users\hulkmtz\Documents\luis angel\Maestria\Asesoria\Semestre 3\Convocatoria\Datos\4 semestre_dataset`

**Asistencia T√©cnica:** Cursor/Claude (IA de desarrollo)  
**√öltima Actualizaci√≥n:** Octubre 18, 2025  
**Versi√≥n del Sistema:** 2.1

---

## üéØ MENSAJE FINAL PARA EL COMIT√â

**Nuestro sistema NO es un modelo predictivo tradicional de Machine Learning.**

Es un **sistema experto h√≠brido** que:
1. ‚úÖ Combina **conocimiento cl√≠nico** (reglas difusas) con **patrones data-driven** (clustering)
2. ‚úÖ Valida la concordancia entre ambos m√©todos (F1=0.84)
3. ‚úÖ Es **interpretable** (cada regla tiene justificaci√≥n fisiol√≥gica)
4. ‚úÖ Captura **heterogeneidad interindividual** (concordancia variable por usuario)
5. ‚úÖ Es **reproducible** (par√°metros fijos, random seeds)

**La validaci√≥n por split 80/20 es:**
- ‚ùå Metodol√≥gicamente incorrecta para series temporales
- ‚ùå Insuficiente en potencia estad√≠stica para 10 usuarios
- ‚ùå No alineada con el objetivo descriptivo-clasificatorio del estudio

**Alternativas robustas disponibles:**
- ‚úÖ Leave-One-User-Out (implementaci√≥n: 1 semana)
- ‚úÖ An√°lisis de sensibilidad (implementaci√≥n: 1 d√≠a)
- ‚úÖ Validaci√≥n temporal (implementaci√≥n: medio d√≠a)

**Decisi√≥n final:** En manos del Comit√© Tutorial.

---

**Gracias por su tiempo y consideraci√≥n.**  
**Esperamos sus comentarios y sugerencias.**

---

**README Preparado por:** Luis √Ångel Mart√≠nez + Cursor/Claude  
**Fecha:** Octubre 18, 2025  
**Versi√≥n:** 1.0




